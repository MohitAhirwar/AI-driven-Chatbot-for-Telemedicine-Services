{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0vt5surQZb-"
      },
      "source": [
        "# Importing Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from typing import List\n",
        "from io import open\n",
        "import unicodedata\n",
        "import random\n",
        "import glob\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "INPUT_LENGTH = 20\n",
        "OUTPUT_LENGTH = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ezZ__KbItnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0888b28a-d483-424e-d71c-11a8f42aee3d"
      },
      "source": [
        "# Reading the dataset\n",
        "df = pd.read_csv(\"final_faq.csv\")\n",
        "df.tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>How long is the incubation period for COVID-19?</td>\n",
              "      <td>The “incubation period” means the time between...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>What is the state doing to protect our health? \\n</td>\n",
              "      <td>California has been actively and extensively p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>What is SARS-CoV-2? What is COVID-19?</td>\n",
              "      <td>Severe Acute Respiratory Syndrome Coronavirus-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>Where do coronaviruses come from?</td>\n",
              "      <td>Coronaviruses are viruses that circulate among...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>Is this virus comparable to SARS or to the sea...</td>\n",
              "      <td>The novel coronavirus detected in China is gen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>How severe is COVID-19 infection?</td>\n",
              "      <td>Preliminary findings indicate that the mortali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>What is the mode of transmission? How (easily)...</td>\n",
              "      <td>While animals are the original source of the v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>What are the symptoms ofÂ COVID-19 infection</td>\n",
              "      <td>The virus can cause mild, flu-like symptoms su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>Are some people more at risk than others?</td>\n",
              "      <td>Generally elderly people and those with underl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>Are children also at risk of infection?</td>\n",
              "      <td>Disease in children appears to be relatively r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Context                                             Answer\n",
              "469    How long is the incubation period for COVID-19?  The “incubation period” means the time between...\n",
              "470  What is the state doing to protect our health? \\n  California has been actively and extensively p...\n",
              "471              What is SARS-CoV-2? What is COVID-19?  Severe Acute Respiratory Syndrome Coronavirus-...\n",
              "472                  Where do coronaviruses come from?  Coronaviruses are viruses that circulate among...\n",
              "473  Is this virus comparable to SARS or to the sea...  The novel coronavirus detected in China is gen...\n",
              "474                  How severe is COVID-19 infection?  Preliminary findings indicate that the mortali...\n",
              "475  What is the mode of transmission? How (easily)...  While animals are the original source of the v...\n",
              "476       What are the symptoms ofÂ COVID-19 infection  The virus can cause mild, flu-like symptoms su...\n",
              "477          Are some people more at risk than others?  Generally elderly people and those with underl...\n",
              "478            Are children also at risk of infection?  Disease in children appears to be relatively r..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wblyf7sLItnd"
      },
      "source": [
        "# Creating QA Lists\n",
        "questions = list(df['Context']);question.append(\"Hello\");question.append(\"How are you ?\");question.append(\"Bye\");\n",
        "answers = list(df['Answer']);answer.append(\"Hi, I am Covid-Bot\");answer.append(\"I am Fine, How can I help u\");answer.append(\"Good Bye\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgyhJIp9Itnd"
      },
      "source": [
        "# Text preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"who's\",\"who is\",text) \n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)  \n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}+=~|.?,]\",\"\",text) \n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb344dA9Itne"
      },
      "source": [
        "# Cleaning the QA Lists \n",
        "clean_questions = []\n",
        "for question in questions:\n",
        "    clean_questions.append(clean_text(question))\n",
        "clean_answers = []    \n",
        "for answer in answers:\n",
        "    clean_answers.append(clean_text(answer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNpShS-3Itnf"
      },
      "source": [
        "lengths = []\n",
        "#nltk method\n",
        "for question in clean_questions:\n",
        "    lengths.append(len(question.split()))\n",
        "for answer in clean_answers:\n",
        "    lengths.append(len(answer.split()))\n",
        "# Create a dataframe\n",
        "lengths = pd.DataFrame(lengths, columns=['counts'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17fg4fTkiCXs",
        "outputId": "d7ba3a15-ff9a-44d6-c4cd-f076a0fd6e4f"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYQYi3xoItng"
      },
      "source": [
        "#tokenizing Q & A (Using ntlk)\n",
        "Q_tok = [nltk.word_tokenize(sent) for sent in questions]\n",
        "A_tok = [nltk.word_tokenize(sent) for sent in answers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuD-GtK5klTy"
      },
      "source": [
        "# \"This is a cooool #smiley: :-) :-P <3 and some arrows < > -> <--\"\n",
        "# ['This', 'is', 'a', 'cooool', '#smiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VQZqPL-Itng"
      },
      "source": [
        "#train-validation split\n",
        "data_size = len(Q_tok)\n",
        "\n",
        "# 80 % training 20% validation\n",
        "training_input  = Q_tok[:round(data_size*(80/100))]\n",
        "training_input  = [tr_input[::-1] for tr_input in training_input] #reversing input seq for better performance\n",
        "training_output = A_tok[:round(data_size*(80/100))]\n",
        "\n",
        "validation_input = Q_tok[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] #reversing input seq for better performance\n",
        "validation_output = A_tok[round(data_size*(80/100)):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXFdwavqItnh"
      },
      "source": [
        "vocab = {}\n",
        "for question in Q_tok:\n",
        "    for word in question:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n",
        "for answer in A_tok:\n",
        "    for word in answer:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOC-cIifItni"
      },
      "source": [
        "threshold = 15\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3umKxi5Itni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e467c6d2-c363-4cb0-92d6-83d1feae231b"
      },
      "source": [
        "WORD_CODE_START = 1\n",
        "WORD_CODE_PADDING = 0\n",
        "word_num  = 2\n",
        "encoding = {}\n",
        "decoding = {1: 'START'}\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold: #get vocabularies that appear above threshold count\n",
        "        encoding[word] = word_num \n",
        "        decoding[word_num ] = word\n",
        "        word_num += 1\n",
        "\n",
        "print(\"No. of vocab used:\", word_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of vocab used: 453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EPdDcWHItnj"
      },
      "source": [
        "decoding[len(encoding)+2] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7CC5UpUItnj"
      },
      "source": [
        "dict_size = word_num+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6m-ALdNItnj"
      },
      "source": [
        "def transform(encoding, data, vector_size=20):\n",
        "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
        "    for i in range(len(data)):\n",
        "        for j in range(min(len(data[i]), vector_size)):\n",
        "            try:\n",
        "                transformed_data[i][j] = encoding[data[i][j]]\n",
        "            except:\n",
        "                transformed_data[i][j] = encoding['<UNK>']\n",
        "    return transformed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfoX5bR-Itnk"
      },
      "source": [
        "#encoding training set\n",
        "encoded_training_input = transform(encoding, training_input, vector_size=INPUT_LENGTH)\n",
        "encoded_training_output = transform(encoding, training_output, vector_size=OUTPUT_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3xBUTHaItnk"
      },
      "source": [
        "#encoding validation set\n",
        "encoded_validation_input = transform(encoding, validation_input, vector_size=INPUT_LENGTH)\n",
        "encoded_validation_output = transform(encoding, validation_output, vector_size=OUTPUT_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rgPPio5Itnl"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyOCaHHMItnl"
      },
      "source": [
        "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
        "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZaJvdZYItnl"
      },
      "source": [
        "from keras.layers import SimpleRNN\n",
        "\n",
        "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
        "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
        "encoder_last = encoder[:,-1,:]\n",
        "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
        "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV4F7rNHItnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c493b808-9e36-4a5a-e6dd-f60d89e4c069"
      },
      "source": [
        "from keras.layers import Activation, dot, concatenate\n",
        "\n",
        "attention = dot([decoder, encoder], axes=[2, 2])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "print('attention', attention)\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
        "print('output', output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention KerasTensor(type_spec=TensorSpec(shape=(None, 20, 20), dtype=tf.float32, name=None), name='attention/Softmax:0', description=\"created by layer 'attention'\")\n",
            "output KerasTensor(type_spec=TensorSpec(shape=(None, 20, 454), dtype=tf.float32, name=None), name='time_distributed_1/Reshape_1:0', description=\"created by layer 'time_distributed_1'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD5BvFB2Eva3"
      },
      "source": [
        "### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZZVaCeiItnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a6fbc1-4db9-4683-bd6e-972b19e0dd4a"
      },
      "source": [
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 128)      58112       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 20, 512)      1312768     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 128)      58112       input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 512)          0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 20, 512)      1312768     embedding_1[0][0]                \n",
            "                                                                 tf.__operators__.getitem_4[0][0] \n",
            "                                                                 tf.__operators__.getitem_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 20, 20)       0           lstm_1[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "attention (Activation)          (None, 20, 20)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 20, 512)      0           attention[0][0]                  \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 1024)     0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 20, 512)      524800      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 20, 454)      232902      time_distributed[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 3,499,462\n",
            "Trainable params: 3,499,462\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGiKtchWItnn"
      },
      "source": [
        "training_encoder_input = encoded_training_input\n",
        "training_decoder_input = np.zeros_like(encoded_training_output)\n",
        "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
        "training_decoder_input[:, 0] = WORD_CODE_START\n",
        "training_decoder_output = np.eye(dict_size)[encoded_training_output.astype('int')]\n",
        "\n",
        "validation_encoder_input = encoded_validation_input\n",
        "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
        "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
        "validation_decoder_input[:, 0] = WORD_CODE_START\n",
        "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONwbbzjFEYN3"
      },
      "source": [
        "### Loading the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9ivhrqItno"
      },
      "source": [
        "from keras import models\n",
        "m = \"model_topic3.h5\"\n",
        "mod = models.load_model(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9mCG6FiEbA-"
      },
      "source": [
        "### Predicting the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aStBDJ1nItno"
      },
      "source": [
        "def prediction(raw_input):\n",
        "    clean_input = clean_text(raw_input)\n",
        "    input_tok = [nltk.word_tokenize(clean_input)]\n",
        "    input_tok = [input_tok[0][::-1]]  #reversing input seq\n",
        "    encoder_input = transform(encoding, input_tok, 20)\n",
        "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
        "    decoder_input[:,0] = WORD_CODE_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        output = mod.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
        "        decoder_input[:,i] = output[:,i]\n",
        "    return output\n",
        "\n",
        "def decode(decoding, vector):\n",
        "    text = ''\n",
        "    for i in vector:\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoding[i]\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgzx7AWLy18f",
        "outputId": "9a8e4609-996c-4bbe-9f5a-0bf6094a64d3"
      },
      "source": [
        "pip install flask_ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75OcOOwqEiwe"
      },
      "source": [
        "### Connecting Backend to Frontend using Flask Framework\n",
        "(Created a home.html file which takes the user text from the front end and then inputs the same string into the model and predict the output from semantic similarity model and it shows the string to the Front end)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mp31eJSy3SB",
        "outputId": "23c5e11d-8d53-4cd7-9454-aa6f94696875"
      },
      "source": [
        "from flask import Flask\n",
        "from flask import Flask, request, render_template\n",
        "from flask_ngrok import run_with_ngrok\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "run_with_ngrok(app)\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"home.html\")\n",
        "\n",
        "@app.route(\"/get\")\n",
        "def get_bot_response():\n",
        "    userText = request.args.get('msg')\n",
        "    output = prediction(userText)\n",
        "    if(output == \"\" or output == \" \" or output == \"  \" or output == \"   \"):\n",
        "        return str(\"Don't Know\")\n",
        "    return str(decode(decoding, output[0]))\n",
        " \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://12dd39557d02.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 04:34:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 04:34:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  app.launch_new_instance()\n",
            "127.0.0.1 - - [22/Jul/2021 04:35:13] \"\u001b[37mGET /get?msg=Why%20corona%3F HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 04:41:41] \"\u001b[37mGET /get?msg=What%20are%20symptoms%20of%20corona%20virs%3F HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 04:42:57] \"\u001b[37mGET /get?msg=What%20about%20animals%20or%20pets%20%3F%20How%20it%20is%20affecting%20them%3F HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 04:43:26] \"\u001b[37mGET /get?msg=What%20about%20animals%20or%20pets HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}